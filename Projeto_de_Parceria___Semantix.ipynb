{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob_fMrRoCWYA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import catboost as ctb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Ignorar avisos para manter a saída mais limpa\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. Análise e Preparação dos Dados ---\n",
        "\n",
        "# Carregar o arquivo ARFF\n",
        "try:\n",
        "    data, meta = arff.loadarff('idosos_varRelevantes.arff')\n",
        "except FileNotFoundError:\n",
        "    print(\"Erro: O arquivo 'idosos_varRelevantes.arff' não foi encontrado.\")\n",
        "    exit()\n",
        "\n",
        "# Converter para DataFrame e preparar os dados\n",
        "df = pd.DataFrame(data)\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = df[col].str.decode('utf-8')\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "for col in df.columns:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "df.dropna(inplace=True)\n",
        "df['class'] = df['class'].astype(int)\n",
        "\n",
        "# Separar variáveis preditoras (X) e alvo (y)\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "# Dividir em conjunto de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- 2. Balanceamento dos Dados de Treino com SMOTE ---\n",
        "print(\"--- Aplicando SMOTE aos dados de treino para balanceamento ---\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "print(f\"Distribuição de classes após SMOTE:\\n{y_train_smote.value_counts()}\\n\")\n",
        "\n",
        "# --- 3. Treinamento dos Novos Modelos ---\n",
        "\n",
        "# --- Modelo 1: Logistic Regression com Cross-Validation ---\n",
        "print(\"--- Treinando LogisticRegressionCV ---\")\n",
        "# O 'cv=5' faz validação cruzada para achar o melhor parâmetro de regularização\n",
        "# 'scoring' focado em 'f1' para otimizar o balanço precisão-recall\n",
        "log_reg_cv = LogisticRegressionCV(cv=5, random_state=42, scoring='f1', max_iter=1000)\n",
        "log_reg_cv.fit(X_train_smote, y_train_smote)\n",
        "print(\"Modelo treinado.\\n\")\n",
        "\n",
        "# --- Modelo 2: Gradient Boosting do Scikit-learn ---\n",
        "print(\"--- Treinando GradientBoostingClassifier ---\")\n",
        "gradient_boosting = GradientBoostingClassifier(n_estimators=150, learning_rate=0.1, random_state=42)\n",
        "gradient_boosting.fit(X_train_smote, y_train_smote)\n",
        "print(\"Modelo treinado.\\n\")\n",
        "\n",
        "# --- Modelo 3: CatBoost (como referência de performance) ---\n",
        "print(\"--- Treinando CatBoost ---\")\n",
        "catboost_smote = ctb.CatBoostClassifier(iterations=100, learning_rate=0.05, random_state=42, verbose=0)\n",
        "catboost_smote.fit(X_train_smote, y_train_smote)\n",
        "print(\"Modelo treinado.\\n\")\n",
        "\n",
        "# --- 4. Avaliação Comparativa ---\n",
        "\n",
        "# Fazer previsões no conjunto de teste (original, não balanceado)\n",
        "y_pred_lr = log_reg_cv.predict(X_test)\n",
        "y_pred_gb = gradient_boosting.predict(X_test)\n",
        "y_pred_cat = catboost_smote.predict(X_test)\n",
        "\n",
        "print(\"--- Resultados Finais: Logistic Regression ---\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(\"--- Resultados Finais: Gradient Boosting ---\")\n",
        "print(classification_report(y_test, y_pred_gb))\n",
        "print(\"--- Resultados Finais: CatBoost ---\")\n",
        "print(classification_report(y_test, y_pred_cat))\n",
        "\n",
        "# --- 5. Geração do Gráfico Comparativo ---\n",
        "\n",
        "# Extrair as métricas para o gráfico\n",
        "report_lr_dict = classification_report(y_test, y_pred_lr, output_dict=True)\n",
        "report_gb_dict = classification_report(y_test, y_pred_gb, output_dict=True)\n",
        "report_cat_dict = classification_report(y_test, y_pred_cat, output_dict=True)\n",
        "\n",
        "# Focaremos nas métricas da Classe 1 e na Acurácia geral\n",
        "metrics_labels = ['Precision (Classe 1)', 'Recall (Classe 1)', 'F1-Score (Classe 1)', 'Accuracy']\n",
        "\n",
        "scores = {\n",
        "    'LogisticRegression': [report_lr_dict['1']['precision'], report_lr_dict['1']['recall'], report_lr_dict['1']['f1-score'], report_lr_dict['accuracy']],\n",
        "    'GradientBoosting': [report_gb_dict['1']['precision'], report_gb_dict['1']['recall'], report_gb_dict['1']['f1-score'], report_gb_dict['accuracy']],\n",
        "    'CatBoost': [report_cat_dict['1']['precision'], report_cat_dict['1']['recall'], report_cat_dict['1']['f1-score'], report_cat_dict['accuracy']],\n",
        "}\n",
        "\n",
        "x = np.arange(len(metrics_labels))\n",
        "width = 0.25\n",
        "fig, ax = plt.subplots(figsize=(16, 9))\n",
        "\n",
        "# Criar as barras para cada modelo\n",
        "rects1 = ax.bar(x - width, scores['LogisticRegression'], width, label='LogisticRegressionCV', color='cornflowerblue')\n",
        "rects2 = ax.bar(x, scores['GradientBoosting'], width, label='GradientBoosting', color='seagreen')\n",
        "rects3 = ax.bar(x + width, scores['CatBoost'], width, label='CatBoost (SMOTE)', color='lightcoral')\n",
        "\n",
        "# Adicionar títulos e labels\n",
        "ax.set_ylabel('Scores', fontsize=14)\n",
        "ax.set_title('Comparação de Desempenho de Novos Modelos (Treinados com SMOTE)', fontsize=16)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics_labels, fontsize=12)\n",
        "ax.legend(fontsize=12)\n",
        "ax.set_ylim(0, 1.1)\n",
        "\n",
        "# Função para adicionar os valores exatos em cima das barras\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.2f}',\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "autolabel(rects3)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "# Plotar gráfico\n",
        "plt.show()"
      ]
    }
  ]
}